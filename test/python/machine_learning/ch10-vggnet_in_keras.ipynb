{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"ch10-vggnet_in_keras.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"UBhZqcXHajHQ"},"source":["#### 10.4.3 CNN 範例 (二)：仿 VGGNet 經典模型"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"DiXli551ajHX"},"source":["import numpy as np\n","np.random.seed(42)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hqapDL28ajHY"},"source":["#### 載入套件"]},{"cell_type":"code","metadata":{"id":"RfqQ2jpuajHY"},"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n","from tensorflow.keras.layers import BatchNormalization\n","#from keras.callbacks import TensorBoard "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"STCx3QcXajHZ"},"source":["#### 下載資料集、預處理"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"u6r3qUkFajHZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629502422053,"user_tz":-480,"elapsed":36976,"user":{"displayName":"Tristan Chang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh12xA8ZXwa1dgzXFsLj_MwkqJdmxu_hK6DdwmvTQ=s64","userId":"01396821554749831700"}},"outputId":"4d89cec0-f77f-4172-fabd-c919269a7b92"},"source":["!pip install tflearn \n","import tflearn.datasets.oxflower17 as oxflower17\n","X, Y = oxflower17.load_data(one_hot=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting tflearn\n","  Downloading tflearn-0.5.0.tar.gz (107 kB)\n","\u001b[?25l\r\u001b[K     |███                             | 10 kB 23.5 MB/s eta 0:00:01\r\u001b[K     |██████                          | 20 kB 20.7 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 30 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 40 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 51 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 61 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 71 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 81 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 92 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 102 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 107 kB 4.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.19.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.15.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from tflearn) (7.1.2)\n","Building wheels for collected packages: tflearn\n","  Building wheel for tflearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tflearn: filename=tflearn-0.5.0-py3-none-any.whl size=127299 sha256=977421fee0ca0431b8fc0ec09e509b49899c505853728ca0dc0eb6507b42b7e7\n","  Stored in directory: /root/.cache/pip/wheels/5f/14/2e/1d8e28cc47a5a931a2fb82438c9e37ef9246cc6a3774520271\n","Successfully built tflearn\n","Installing collected packages: tflearn\n","Successfully installed tflearn-0.5.0\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n","Downloading Oxford 17 category Flower Dataset, Please wait...\n"],"name":"stdout"},{"output_type":"stream","text":["100.0% 60276736 / 60270631\n"],"name":"stderr"},{"output_type":"stream","text":["Succesfully downloaded 17flowers.tgz 60270631 bytes.\n","File Extracted\n","Starting to parse images...\n","Parsing Done!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"54uPBTO6ajHa"},"source":["#### 規劃模型架構"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"Itwz5ki2ajHa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629502422639,"user_tz":-480,"elapsed":599,"user":{"displayName":"Tristan Chang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh12xA8ZXwa1dgzXFsLj_MwkqJdmxu_hK6DdwmvTQ=s64","userId":"01396821554749831700"}},"outputId":"2c8c4de7-3bbd-4ff5-de25-d47841a7f797"},"source":["model = Sequential()\n","\n","model.add(Conv2D(64, 3, activation='relu', input_shape=(224, 224, 3)))\n","model.add(Conv2D(64, 3, activation='relu'))\n","model.add(MaxPooling2D(2, 2))\n","model.add(BatchNormalization())\n","\n","model.add(Conv2D(128, 3, activation='relu'))\n","model.add(Conv2D(128, 3, activation='relu'))\n","model.add(MaxPooling2D(2, 2))\n","model.add(BatchNormalization())\n","\n","model.add(Conv2D(256, 3, activation='relu'))\n","model.add(Conv2D(256, 3, activation='relu'))\n","model.add(Conv2D(256, 3, activation='relu'))\n","model.add(MaxPooling2D(2, 2))\n","model.add(BatchNormalization())\n","\n","model.add(Conv2D(512, 3, activation='relu'))\n","model.add(Conv2D(512, 3, activation='relu'))\n","model.add(Conv2D(512, 3, activation='relu'))\n","model.add(MaxPooling2D(2, 2))\n","model.add(BatchNormalization())\n","\n","model.add(Conv2D(512, 3, activation='relu'))\n","model.add(Conv2D(512, 3, activation='relu'))\n","model.add(Conv2D(512, 3, activation='relu'))\n","model.add(MaxPooling2D(2, 2))\n","model.add(BatchNormalization())\n","\n","model.add(Flatten())\n","model.add(Dense(4096, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(4096, activation='relu'))\n","model.add(Dropout(0.5))\n","\n","model.add(Dense(17, activation='softmax'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/layers/normalization/batch_normalization.py:520: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wUOIF6QGajHb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629502422640,"user_tz":-480,"elapsed":6,"user":{"displayName":"Tristan Chang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh12xA8ZXwa1dgzXFsLj_MwkqJdmxu_hK6DdwmvTQ=s64","userId":"01396821554749831700"}},"outputId":"c2381775-e1dc-4793-c1fd-5c76364c2b39"},"source":["model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 222, 222, 64)      1792      \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 220, 220, 64)      36928     \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 110, 110, 64)      0         \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 110, 110, 64)      256       \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 108, 108, 128)     73856     \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 106, 106, 128)     147584    \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 53, 53, 128)       0         \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 53, 53, 128)       512       \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 51, 51, 256)       295168    \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 49, 49, 256)       590080    \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 47, 47, 256)       590080    \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 23, 23, 256)       0         \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 23, 23, 256)       1024      \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 21, 21, 512)       1180160   \n","_________________________________________________________________\n","conv2d_8 (Conv2D)            (None, 19, 19, 512)       2359808   \n","_________________________________________________________________\n","conv2d_9 (Conv2D)            (None, 17, 17, 512)       2359808   \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 8, 8, 512)         0         \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 8, 8, 512)         2048      \n","_________________________________________________________________\n","conv2d_10 (Conv2D)           (None, 6, 6, 512)         2359808   \n","_________________________________________________________________\n","conv2d_11 (Conv2D)           (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","conv2d_12 (Conv2D)           (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 1, 1, 512)         2048      \n","_________________________________________________________________\n","flatten (Flatten)            (None, 512)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 4096)              2101248   \n","_________________________________________________________________\n","dropout (Dropout)            (None, 4096)              0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 4096)              16781312  \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 4096)              0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 17)                69649     \n","=================================================================\n","Total params: 33,672,785\n","Trainable params: 33,669,841\n","Non-trainable params: 2,944\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SC8X2BKvajHc"},"source":["#### 編譯模型"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"wfggQzrbajHc"},"source":["model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"utJ4j4yVajHd"},"source":["#### 訓練模型"]},{"cell_type":"code","metadata":{"id":"i0hkBpcPajHd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629520365538,"user_tz":-480,"elapsed":3126721,"user":{"displayName":"Tristan Chang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh12xA8ZXwa1dgzXFsLj_MwkqJdmxu_hK6DdwmvTQ=s64","userId":"01396821554749831700"}},"outputId":"d27cbd5f-21cf-4510-b87e-e29113e9af74"},"source":["#註：由於神經網路的初始權重參數是隨機設定的, 參雜了隨機性, 因此底下 (或您重跑一次) 的結果不會與書中完全一樣, 但模型的能力是相近的\n","#註：此模型執行時間較長，每一週期約需 20～30 分鐘不等。\n","model.fit(X, Y, batch_size=64, epochs=240, verbose=1, validation_split=0.1, shuffle=True) # callbacks=[tensorbrd])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train on 1224 samples, validate on 136 samples\n","Epoch 1/2\n","1224/1224 [==============================] - 1559s 1s/sample - loss: 1.6800 - acc: 0.3783 - val_loss: 5.0635 - val_acc: 0.0441\n","Epoch 2/2\n","1224/1224 [==============================] - 1567s 1s/sample - loss: 1.8228 - acc: 0.3391 - val_loss: 2.8983 - val_acc: 0.1176\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f4a1be9ec90>"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"collapsed":true,"id":"KYZ06A5hajHe"},"source":[""],"execution_count":null,"outputs":[]}]}